{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44b7dbdc",
   "metadata": {},
   "source": [
    "**Команды для запуска**\n",
    "\n",
    "conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia\n",
    "\n",
    "conda install -c conda-forge notebook\n",
    "\n",
    "pip install opencv-python\n",
    "\n",
    "conda install -c conda-forge tqdm\n",
    "\n",
    "pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b63cf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import ffmpeg\n",
    "import IPython.display\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1db7906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "torch.set_num_threads(os.cpu_count())\n",
    "\n",
    "vad_model, vad_utils = torch.hub.load(repo_or_dir='silero-vad',\n",
    "                                                   model='silero_vad',\n",
    "                                                   source='local',\n",
    "                                                   force_reload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "126f5334",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoCamera:\n",
    "    def __init__(self, \n",
    "                path_video: str = '', \n",
    "                path_save_ims_txt: str = '',\n",
    "                path_save_df: str = '', \n",
    "                multiple: int = 10,\n",
    "                vad_model = None,\n",
    "                vad_utils = None):\n",
    "        self.path_video = path_video\n",
    "        self.path_save_ims_txt = path_save_ims_txt\n",
    "        self.path_save_df = path_save_df\n",
    "        self.multiple = multiple # шаг прореживания кадров\n",
    "        self.c_fr = 1 # счетчик для кадров\n",
    "        self.video = None\n",
    "        self.total_frames = None\n",
    "        self.vad_model, self.vad_utils = vad_model, vad_utils\n",
    "        self.get_speech_timestamps, _, self.read_audio, _, _ = self.vad_utils\n",
    "\n",
    "    def __del__(self):\n",
    "        self.video.release()\n",
    "        \n",
    "    def norm_coordinates(self, normalized_x, normalized_y, image_width, image_height):\n",
    "\n",
    "        x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
    "        y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
    "\n",
    "        return x_px, y_px\n",
    "\n",
    "    def get_box(self, fl, w, h):\n",
    "        idx_to_coors = {}\n",
    "        for idx, landmark in enumerate(fl.landmark):\n",
    "            if ((landmark.HasField('visibility') and\n",
    "                 landmark.visibility < _VISIBILITY_THRESHOLD) or\n",
    "                (landmark.HasField('presence') and\n",
    "                 landmark.presence < _PRESENCE_THRESHOLD)):\n",
    "                continue\n",
    "            landmark_px = self.norm_coordinates(landmark.x, landmark.y, w, h)\n",
    "\n",
    "            if landmark_px:\n",
    "                \"\"\"\n",
    "                Записать в словарь idx_to_coors значения координаты landmark_px по нужному ключу idx\n",
    "                \"\"\"\n",
    "                idx_to_coors[idx] = landmark_px\n",
    "        \"\"\"\n",
    "        Найти минимальные и максимальные значения координат x и y.\n",
    "        \"\"\"\n",
    "        x_min = min( [point[0] for point in idx_to_coors.values()] )\n",
    "        y_min = min( [point[1] for point in idx_to_coors.values()] )\n",
    "        x_max = max( [point[0] for point in idx_to_coors.values()] )\n",
    "        y_max = max( [point[1] for point in idx_to_coors.values()] )\n",
    "        \n",
    "        \"\"\"\n",
    "        Обновить минимальные и максимальные значения координат x и y по принципу:\n",
    "        1) если x_min и/или y_min меньше 0, то x_min и/или y_min равны 0\n",
    "        2) если x_max и y_max больше w и h, то установить значения x_max=w-1, y_max=h-1\n",
    "        \"\"\"\n",
    "        (x_min, y_min) = max(0, x_min), max(0, y_min)\n",
    "        (x_max, y_max) = min(w - 1, x_max), min(h - 1, y_max)\n",
    "        \n",
    "        return x_min, y_min, x_max, y_max\n",
    "        \n",
    "    def norm_box(self, size=None, box=None):\n",
    "        \"\"\"\n",
    "        Написать метод нормализации координат ограничительных рамок лица. Входные переменные метода:\n",
    "        - size=(w,h), где w - ширина кадра, h высота кадра\n",
    "        - box = x_min, y_min, x_max, y_max\n",
    "        \n",
    "        1) Нормализовать значения dw, dh, по принципу:   \n",
    "            - 1/size[0]\n",
    "            - 1/size[0]\n",
    "        2) Найти значения центральных координат сx и сy для значений (x_min, x_max) и (y_min, y_max) учетом вычета 1 из обоих центральных координат.\n",
    "        3) Найти ширину fw и высоту fh лица используя координаты (x_min, x_max) и (y_min, y_max).\n",
    "        4) Нормализовать значения сx и fw на величину dw, сy и fh на величину dh путем перемножения.\n",
    "        \"\"\"\n",
    "\n",
    "        x_min, y_min, x_max, y_max = box\n",
    "\n",
    "        dw = 1 / size[0]\n",
    "        dh = 1 / size[1]\n",
    "        \n",
    "        cx = (x_max + x_min) / 2 - 1\n",
    "        cy = (y_max + y_min) / 2 - 1\n",
    "        \n",
    "        \n",
    "        fw = x_max - x_min\n",
    "        fh = y_max - y_min\n",
    "        \n",
    "        cx = dw * cx\n",
    "        cy = dh * cy\n",
    "        fw = dw * fw\n",
    "        fh = dh * fh\n",
    "        return [cx,cy,fw,fh]\n",
    "    \n",
    "    def get_timestamps(self):\n",
    "        \"\"\"\n",
    "        Написать метод, который работает со свойствами класса VideoCamera:\n",
    "        - self.path_video, \n",
    "        - self.read_audio, \n",
    "        - self.get_speech_timestamps,\n",
    "        - self.vad_model.\n",
    "        Возвращает:\n",
    "        1) время начала речи в секундах;\n",
    "        2) время конца речи в секундах.\n",
    "        \n",
    "        Для определения границ речи воспользуемся silero. \n",
    "        Silero принимает на вход разрешения файл разрешения wav.\n",
    "        1) Необходимо конвертнуть видео файл формата mp4 в аудиофайл формата wav, выполнив команду:\n",
    "           os.system(\"ffmpeg -i path_video -vn -acodec pcm_s16le -ar 16000 -ac 2 save_path_audio\")\n",
    "           где path_video=self.path_video, save_path_audio - путь к для сохранения аудио файла.\n",
    "        2) Воспользуйтесь свойством класса self.read_audio(save_path_audio, sampling_rate=16000), чтобы считать wav файл.\n",
    "        3) Удалить wav файл с помощью os.remove(), можно конечно не удалять wav файл, но он вам больше не понадобится.\n",
    "        3) Воспользуйтесь свойством класса self.get_speech_timestamps(wav, self.vad_model, sampling_rate=16000), чтобы получить границы речи.\n",
    "        4) Переведите границы речи из отсчетов в секунды.\n",
    "        \n",
    "        Внимание!!!\n",
    "        \n",
    "        Silero может выдавать список словарей с несколькими границами речи, \n",
    "        поэтому рекомендуется использовать начало речи нулевого элемента по ключу 'start',\n",
    "        конец речи -1 элемента по ключу 'end'.\n",
    "        \"\"\"\n",
    "\n",
    "        out, _ = ffmpeg.input(self.path_video).audio.output('-', format = 'wav', acodec = 'pcm_s16le', ac = 1, ar=16000).run(quiet=True)\n",
    "        \n",
    "        wav = np.frombuffer(out, np.int16)\n",
    "\n",
    "        wav = torch.Tensor(wav)\n",
    "        \n",
    "        speech_timestamps = self.get_speech_timestamps(wav, self.vad_model, sampling_rate=16000)\n",
    "        if len(speech_timestamps) >= 1: # если вад нашел границы речи\n",
    "            start = speech_timestamps[0]['start'] / 16000 # работаем с speech_timestamps\n",
    "            end = speech_timestamps[-1]['end'] / 16000 # работаем с speech_timestamps\n",
    "        else: # в противном случае\n",
    "            start, end = 0, len(wav) / 16000\n",
    "        return start, end\n",
    "   \n",
    "    def get_id_cl(self):\n",
    "        \"\"\"\n",
    "        Написать метод, который работает со свойством self.path_video класса VideoCamera.\n",
    "        Возвращает:\n",
    "        1) имя видеофайла (n_v) без расширения, например 1010_DFA_ANG_XX;\n",
    "        2) индекс эмоции (id_cl) \n",
    "        \n",
    "        Внимание!!! \n",
    "        \n",
    "        Имя каждого файла зашифровано. Пример, расшифровки для 1010_DFA_ANG_XX.flv.\n",
    "        \n",
    "        1010 - уникальный номер актера.\n",
    "        DFA - произносимая фраза.\n",
    "        ANG - имитируемая эмоция.\n",
    "        XX - интенсивность эмоции\n",
    "        \n",
    "        Вам понадобятся знания только об унимальном номере актера и имитируемая эмоция.\n",
    "        Всего 6 эмоций:\n",
    "        - Anger (ANG) - присвоить уникальный номер класса эмоции 0\n",
    "        - Disgust (DIS) - присвоить уникальный номер класса эмоции 1\n",
    "        - Fear (FEA) - присвоить уникальный номер класса эмоции 2\n",
    "        - Happy/Joy (HAP) - присвоить уникальный номер класса эмоции 3\n",
    "        - Neutral (NEU) - присвоить уникальный номер класса эмоции 4\n",
    "        - Sad (SAD) - присвоить уникальный номер класса эмоции 5\n",
    "        \n",
    "        1) Необходимо получить имя файла без расширения.\n",
    "        2) Преобразовать название эмоции в его индекс, например ANG - 0.\n",
    "        \"\"\"\n",
    "\n",
    "        emotions = {\n",
    "            'ANG': 0,\n",
    "            'DIS': 1,\n",
    "            'FEA': 2,\n",
    "            'HAP': 3,\n",
    "            'NEU': 4,\n",
    "            'SAD': 5,\n",
    "        }\n",
    "\n",
    "        n_v = os.path.splitext(os.path.basename(self.path_video))[0]\n",
    "        id_cl = emotions[ n_v.split('_')[-2] ]\n",
    "        return n_v, id_cl\n",
    "    \n",
    "    def makedirs(self, n_v):\n",
    "        \"\"\"\n",
    "        Написать метод, который проверяет, существует ли папка для сохранения кадров и txt файлов.\n",
    "        При отсутствии папки создать ее. Использовать библиотеку os.\n",
    "        Путь для сохранения должен состоять из  self.path_save_ims_txt, n_v.\n",
    "        Пример пути для сохранения кадров и txt файлов: .\\CREMA_D_img_txt\\1010_DFA_ANG_XX\\.\n",
    "        \n",
    "        Работает со:\n",
    "        1) свойством self.path_save_ims_txt\n",
    "        Принимает на вход:\n",
    "        1) имя видеофайла (n_v).\n",
    "        Возвращает:\n",
    "        1) путь (c_path) для сохранения кадров и txt файлов\n",
    "        \"\"\"\n",
    "        c_path = os.path.join(self.path_save_ims_txt, n_v, '')\n",
    "        if not os.path.exists(c_path):\n",
    "            os.makedirs(c_path)\n",
    "        return c_path\n",
    "            \n",
    "    def save_txt(self, c_path: str, n_img: int, line_need: tuple) -> None:\n",
    "        \"\"\"\n",
    "        Написать метод для сохранения line_need в 1 txt файл.\n",
    "        Пример пути для сохранения txt: .\\CREMA_D_img_txt\\1010_DFA_ANG_XX\\000001.txt\n",
    "        \n",
    "        Принимает на вход:\n",
    "        1) путь (c_path) для сохранения кадров и txt файлов\n",
    "        2) текущее имя кадра (n_img) \n",
    "        3) кортеж (line_need)\n",
    "        Возвращает:\n",
    "        1) Ничего\n",
    "        \"\"\"\n",
    "        with open(os.path.join(c_path, n_img) + '.txt', 'w') as f:\n",
    "            # преобразовать line_need, пример:\n",
    "            # из (0, 0.525, 0.451172, 0.3375, 0.511719)\n",
    "            # в '0 0.525 0.451172 0.3375 0.511719\\n'\n",
    "            new_line = ' '.join([str(el) for el in line_need]).strip() + '\\n'\n",
    "            f.write(new_line)\n",
    "            \n",
    "    def save_img(self, c_path, n_img):\n",
    "        \n",
    "        \"\"\"\n",
    "        Написать метод для сохранения кадров.\n",
    "        Пример пути для сохранения кадров: .\\CREMA_D_img_txt\\1010_DFA_ANG_XX\\000010.jpg\n",
    "        \n",
    "        Работает со:\n",
    "        1) свойством self.fr\n",
    "        Принимает на вход:\n",
    "        1) путь (c_path) для сохранения кадров и txt файлов\n",
    "        2) текущее имя кадра (n_img) \n",
    "        Возвращает:\n",
    "        1) Ничего\n",
    "        \"\"\"\n",
    "        cv2.imwrite(os.path.join(c_path, n_img) +'.jpg', self.fr)\n",
    "        \n",
    "    def create_df(self):\n",
    "        \"\"\"\n",
    "        Написать метод проверки существует ли датафрейм с метаданными видео\n",
    "        и при отсутствии датафрейма создать его.\n",
    "        Названия столбцов датафрейма:\n",
    "        name_video - имя файла без расширения\n",
    "        id_classes - индекс эмоции, представленной на видео\n",
    "        speech_duration - продолжительность речи\n",
    "        \n",
    "        Работает со:\n",
    "        1) свойством self.path_save_df\n",
    "        Принимает на вход:\n",
    "        1) Ничего\n",
    "        Возвращает:\n",
    "        1) Ничего\n",
    "        \"\"\"\n",
    "        if not os.path.exists(self.path_save_df):\n",
    "            # создать пустой датафрейм c заданными наименованиями столбцов\n",
    "            df = pd.DataFrame(columns=['name_video', 'id_classes', 'speech_duration'])\n",
    "            # сохранить датафрейм\n",
    "            df.to_csv(self.path_save_df, index=False)\n",
    "    \n",
    "    def get_frame(self):\n",
    "        self.video = cv2.VideoCapture(self.path_video)  \n",
    "        fps = np.round(self.video.get(cv2.CAP_PROP_FPS)) # получаем информацио о fps видео\n",
    "        w = int(self.video.get(cv2.CAP_PROP_FRAME_WIDTH)) # получаем информацио о ширине кадра\n",
    "        h = int(self.video.get(cv2.CAP_PROP_FRAME_HEIGHT)) # получаем информацио о высоте кадра\n",
    "        self.total_frame = int(self.video.get(cv2.CAP_PROP_FRAME_COUNT)) # получаем информацию об общем количестве кадров\n",
    "        \"\"\"\n",
    "        1. Написать и вызвать метод self.get_timestamps для получения начала и конца речи с помощью silero\n",
    "        \"\"\"\n",
    "        start, end = self.get_timestamps()\n",
    "        \"\"\"\n",
    "        2. Перевести время с секунд в кадры. Сформировать список need_frames нужных прореженных кадров, \n",
    "        используя start, end, self.multiple. \n",
    "        \"\"\"\n",
    "        need_frames = list(range( int(start * fps), int(end * fps) + 1, self.multiple ))\n",
    "        \"\"\"\n",
    "        3. Написать и вызвать метод self.get_id_cl()\n",
    "        \"\"\"\n",
    "        n_v, id_cl = self.get_id_cl()\n",
    "        \n",
    "        with mp_face_mesh.FaceMesh(\n",
    "                max_num_faces=1,\n",
    "                refine_landmarks=False,\n",
    "                min_detection_confidence=0.5,\n",
    "                min_tracking_confidence=0.5) as face_mesh:\n",
    "        \n",
    "            while True:\n",
    "                _, self.fr = self.video.read()\n",
    "                if self.fr is None: break\n",
    "                    \n",
    "                \"\"\"\n",
    "                4. Написать условие: если текущий кадр self.c_fr есть в списке need_frames, то выполнить обнаружение лица\n",
    "                \"\"\"\n",
    "                if self.c_fr in need_frames: \n",
    "                    \n",
    "                    n_img = str(self.c_fr).zfill(6)\n",
    "\n",
    "                    self.fr.flags.writeable = False\n",
    "                    self.fr = cv2.cvtColor(self.fr, cv2.COLOR_BGR2RGB)\n",
    "                    results = face_mesh.process(self.fr)\n",
    "\n",
    "                    self.fr.flags.writeable = True\n",
    "                    self.fr = cv2.cvtColor(self.fr, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                    if results.multi_face_landmarks:\n",
    "                        for fl in results.multi_face_landmarks:\n",
    "                            box = self.get_box(fl, w, h) # Дописать код\n",
    "                            newbox = self.norm_box(size=(w, h), box=box) # Дописать код\n",
    "                            line_need = (id_cl, *newbox)\n",
    "                            \"\"\"\n",
    "                            5. Написать и вызвать метод self.makedirs() для сознания пути сохранения изображений и текстовых файлов.\n",
    "                            \"\"\"\n",
    "                            c_path = self.makedirs(n_v = n_v)\n",
    "                            \"\"\"\n",
    "                            6. Написать и вызвать метод self.save_txt() для сохранения текстовых файлов.\n",
    "                            \"\"\"\n",
    "                            self.save_txt(c_path = c_path, n_img = n_img, line_need = line_need)\n",
    "                            \"\"\"\n",
    "                            7. Написать и вызвать метод self.save_img() для сохранения изображений.\n",
    "                            \"\"\"\n",
    "                            self.save_img(c_path = c_path, n_img = n_img)\n",
    "                self.c_fr += 1\n",
    "        \"\"\"\n",
    "        8. Написать и вызвать метод self.create_df() для создания или проверки существования датафрейма с метаданными\n",
    "        \"\"\"        \n",
    "                \n",
    "        self.create_df()\n",
    "        \n",
    "        \"\"\"\n",
    "        9. Сохранить метаданные о видео:\n",
    "        - name_video,\n",
    "        - id_classes,\n",
    "        - speech_duration (указать продолжительность речи, использовать значения start и end)\n",
    "        \"\"\"  \n",
    "        with open(self.path_save_df, 'a+', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter=',')\n",
    "            writer.writerow([n_v, id_cl, end - start])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b07fe4ae-07ae-4a9c-bc7d-3d27b89d22f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 6948/6948 [33:30<00:00,  3.46it/s]\n",
      "100%|████████████████████████████████████████████████████| 492/492 [02:18<00:00,  3.56it/s]\n"
     ]
    }
   ],
   "source": [
    "path_dataset = 'CREMA-D/' # Пропишите путь к видеоданным\n",
    "path_save_img_txt_train = 'CREMA_D_img_txt/train/' # Пропишите путь к сохранению обучающий данных\n",
    "path_save_img_txt_test = 'CREMA_D_img_txt/test/' # Пропишите путь к сохранению тестовых данных\n",
    "path_save_df = 'CREMA_D_img_txt/df_record.csv' # Пропишите путь к сохранению метаданных о видео\n",
    "\n",
    "files = os.listdir(path_dataset) #Используйте os.listdir() для считывания всех видеоданных\n",
    "\n",
    "\"\"\"\n",
    "1) Отберите спикеров для обучения и тестирования\n",
    "    Имя каждого файла зашифровано. Пример, расшифровки для 1010_DFA_ANG_XX.flv.\n",
    "            \n",
    "    1010 - уникальный номер актера.\n",
    "    DFA - произносимая фраза.\n",
    "    ANG - имитируемая эмоция.\n",
    "    XX - интенсивность эмоции\n",
    "    \n",
    "    Отбираем спикеров по уникальному номеру актера. \n",
    "\"\"\"\n",
    "\n",
    "train_files = [file for file in files if int(file.split('_')[0]) not in range(1078, 1083 + 1)]\n",
    "test_files = [file for file in files if int(file.split('_')[0]) in range(1078, 1083 + 1)]\n",
    "\n",
    "for file in tqdm(train_files):\n",
    "    detect = VideoCamera(path_video=os.path.join(path_dataset, file), path_save_ims_txt=path_save_img_txt_train, path_save_df=path_save_df, multiple=10, vad_model=vad_model, vad_utils=vad_utils)\n",
    "    detect.get_frame()\n",
    "    IPython.display.clear_output(wait=True)\n",
    "\n",
    "for file in tqdm(test_files):\n",
    "    detect = VideoCamera(path_video=os.path.join(path_dataset, file), path_save_ims_txt=path_save_img_txt_test, path_save_df=path_save_df, multiple=10, vad_model=vad_model, vad_utils=vad_utils)\n",
    "    detect.get_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2c2a699-9674-47f0-812c-15df9e34c953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>id_classes</th>\n",
       "      <th>ANG</th>\n",
       "      <th>DIS</th>\n",
       "      <th>FEA</th>\n",
       "      <th>HAP</th>\n",
       "      <th>NEU</th>\n",
       "      <th>SAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>speech_duration</th>\n",
       "      <td>1.924418</td>\n",
       "      <td>1.877323</td>\n",
       "      <td>1.510478</td>\n",
       "      <td>1.640052</td>\n",
       "      <td>1.743077</td>\n",
       "      <td>1.54966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "id_classes            ANG       DIS       FEA       HAP       NEU      SAD\n",
       "speech_duration  1.924418  1.877323  1.510478  1.640052  1.743077  1.54966"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions = {\n",
    "        'ANG': 0,\n",
    "        'DIS': 1,\n",
    "        'FEA': 2,\n",
    "        'HAP': 3,\n",
    "        'NEU': 4,\n",
    "        'SAD': 5,\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "path_save_df = 'CREMA_D_img_txt/df_record.csv' # Пропишите путь к сохранению метаданных о видео\n",
    "df = pd.read_csv(path_save_df)\n",
    "df.id_classes = df.id_classes.map({v: k for k, v in emotions.items()})\n",
    "pd.DataFrame(df.groupby(by='id_classes')['speech_duration'].mean()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f31417-087f-4840-aaed-fde0f272f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoCamera:\n",
    "    def __init__(self, \n",
    "                path_video: str = '', \n",
    "                path_save_ims_txt: str = '',\n",
    "                path_save_df: str = '', \n",
    "                multiple: int = 10,\n",
    "                vad_model = None,\n",
    "                vad_utils = None):\n",
    "        self.path_video = path_video\n",
    "        self.path_save_ims_txt = path_save_ims_txt\n",
    "        self.path_save_df = path_save_df\n",
    "        self.multiple = multiple # шаг прореживания кадров\n",
    "        self.c_fr = 1 # счетчик для кадров\n",
    "        self.video = None\n",
    "        self.total_frames = None\n",
    "        self.vad_model, self.vad_utils = vad_model, vad_utils\n",
    "        self.get_speech_timestamps, _, self.read_audio, _, _ = self.vad_utils\n",
    "\n",
    "    def __del__(self):\n",
    "        self.video.release()\n",
    "        \n",
    "    def norm_coordinates(self, normalized_x, normalized_y, image_width, image_height):\n",
    "\n",
    "        x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
    "        y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
    "\n",
    "        return x_px, y_px\n",
    "\n",
    "    def get_box(self, fl, w, h):\n",
    "        idx_to_coors = {}\n",
    "        for idx, landmark in enumerate(fl.landmark):\n",
    "            if ((landmark.HasField('visibility') and\n",
    "                 landmark.visibility < _VISIBILITY_THRESHOLD) or\n",
    "                (landmark.HasField('presence') and\n",
    "                 landmark.presence < _PRESENCE_THRESHOLD)):\n",
    "                continue\n",
    "            landmark_px = self.norm_coordinates(landmark.x, landmark.y, w, h)\n",
    "\n",
    "            if landmark_px:\n",
    "                \"\"\"\n",
    "                Записать в словарь idx_to_coors значения координаты landmark_px по нужному ключу idx\n",
    "                \"\"\"\n",
    "                idx_to_coors[idx] = landmark_px\n",
    "        \"\"\"\n",
    "        Найти минимальные и максимальные значения координат x и y.\n",
    "        \"\"\"\n",
    "        x_min = min( [point[0] for point in idx_to_coors.values()] )\n",
    "        y_min = min( [point[1] for point in idx_to_coors.values()] )\n",
    "        x_max = max( [point[0] for point in idx_to_coors.values()] )\n",
    "        y_max = max( [point[1] for point in idx_to_coors.values()] )\n",
    "        \n",
    "        \"\"\"\n",
    "        Обновить минимальные и максимальные значения координат x и y по принципу:\n",
    "        1) если x_min и/или y_min меньше 0, то x_min и/или y_min равны 0\n",
    "        2) если x_max и y_max больше w и h, то установить значения x_max=w-1, y_max=h-1\n",
    "        \"\"\"\n",
    "        (x_min, y_min) = max(0, x_min), max(0, y_min)\n",
    "        (x_max, y_max) = min(w - 1, x_max), min(h - 1, y_max)\n",
    "        \n",
    "        return x_min, y_min, x_max, y_max\n",
    "        \n",
    "    def norm_box(self, size=None, box=None):\n",
    "        \"\"\"\n",
    "        Написать метод нормализации координат ограничительных рамок лица. Входные переменные метода:\n",
    "        - size=(w,h), где w - ширина кадра, h высота кадра\n",
    "        - box = x_min, y_min, x_max, y_max\n",
    "        \n",
    "        1) Нормализовать значения dw, dh, по принципу:   \n",
    "            - 1/size[0]\n",
    "            - 1/size[0]\n",
    "        2) Найти значения центральных координат сx и сy для значений (x_min, x_max) и (y_min, y_max) учетом вычета 1 из обоих центральных координат.\n",
    "        3) Найти ширину fw и высоту fh лица используя координаты (x_min, x_max) и (y_min, y_max).\n",
    "        4) Нормализовать значения сx и fw на величину dw, сy и fh на величину dh путем перемножения.\n",
    "        \"\"\"\n",
    "\n",
    "        x_min, y_min, x_max, y_max = box\n",
    "\n",
    "        dw = 1 / size[0]\n",
    "        dh = 1 / size[1]\n",
    "        \n",
    "        cx = (x_max + x_min) / 2 - 1\n",
    "        cy = (y_max + y_min) / 2 - 1\n",
    "        \n",
    "        \n",
    "        fw = x_max - x_min\n",
    "        fh = y_max - y_min\n",
    "        \n",
    "        cx = dw * cx\n",
    "        cy = dh * cy\n",
    "        fw = dw * fw\n",
    "        fh = dh * fh\n",
    "        return [cx,cy,fw,fh]\n",
    "    \n",
    "    def get_timestamps(self):\n",
    "        \"\"\"\n",
    "        Написать метод, который работает со свойствами класса VideoCamera:\n",
    "        - self.path_video, \n",
    "        - self.read_audio, \n",
    "        - self.get_speech_timestamps,\n",
    "        - self.vad_model.\n",
    "        Возвращает:\n",
    "        1) время начала речи в секундах;\n",
    "        2) время конца речи в секундах.\n",
    "        \n",
    "        Для определения границ речи воспользуемся silero. \n",
    "        Silero принимает на вход разрешения файл разрешения wav.\n",
    "        1) Необходимо конвертнуть видео файл формата mp4 в аудиофайл формата wav, выполнив команду:\n",
    "           os.system(\"ffmpeg -i path_video -vn -acodec pcm_s16le -ar 16000 -ac 2 save_path_audio\")\n",
    "           где path_video=self.path_video, save_path_audio - путь к для сохранения аудио файла.\n",
    "        2) Воспользуйтесь свойством класса self.read_audio(save_path_audio, sampling_rate=16000), чтобы считать wav файл.\n",
    "        3) Удалить wav файл с помощью os.remove(), можно конечно не удалять wav файл, но он вам больше не понадобится.\n",
    "        3) Воспользуйтесь свойством класса self.get_speech_timestamps(wav, self.vad_model, sampling_rate=16000), чтобы получить границы речи.\n",
    "        4) Переведите границы речи из отсчетов в секунды.\n",
    "        \n",
    "        Внимание!!!\n",
    "        \n",
    "        Silero может выдавать список словарей с несколькими границами речи, \n",
    "        поэтому рекомендуется использовать начало речи нулевого элемента по ключу 'start',\n",
    "        конец речи -1 элемента по ключу 'end'.\n",
    "        \"\"\"\n",
    "\n",
    "        out, _ = ffmpeg.input(self.path_video).audio.output('-', format = 'wav', acodec = 'pcm_s16le', ac = 1, ar=16000).run(quiet=True)\n",
    "        \n",
    "        wav = np.frombuffer(out, np.int16)\n",
    "\n",
    "        wav = torch.Tensor(wav)\n",
    "        \n",
    "        speech_timestamps = self.get_speech_timestamps(wav, self.vad_model, sampling_rate=16000)\n",
    "        if len(speech_timestamps) >= 1: # если вад нашел границы речи\n",
    "            start = speech_timestamps[0]['start'] / 16000 # работаем с speech_timestamps\n",
    "            end = speech_timestamps[-1]['end'] / 16000 # работаем с speech_timestamps\n",
    "        else: # в противном случае\n",
    "            start, end = 0, len(wav) / 16000\n",
    "        return start, end\n",
    "   \n",
    "    def get_id_cl(self):\n",
    "        \"\"\"\n",
    "        Написать метод, который работает со свойством self.path_video класса VideoCamera.\n",
    "        Возвращает:\n",
    "        1) имя видеофайла (n_v) без расширения, например 1010_DFA_ANG_XX;\n",
    "        2) индекс эмоции (id_cl) \n",
    "        \n",
    "        Внимание!!! \n",
    "        \n",
    "        Имя каждого файла зашифровано. Пример, расшифровки для 1010_DFA_ANG_XX.flv.\n",
    "        \n",
    "        1010 - уникальный номер актера.\n",
    "        DFA - произносимая фраза.\n",
    "        ANG - имитируемая эмоция.\n",
    "        XX - интенсивность эмоции\n",
    "        \n",
    "        Вам понадобятся знания только об унимальном номере актера и имитируемая эмоция.\n",
    "        Всего 6 эмоций:\n",
    "        - Anger (ANG) - присвоить уникальный номер класса эмоции 0\n",
    "        - Disgust (DIS) - присвоить уникальный номер класса эмоции 1\n",
    "        - Fear (FEA) - присвоить уникальный номер класса эмоции 2\n",
    "        - Happy/Joy (HAP) - присвоить уникальный номер класса эмоции 3\n",
    "        - Neutral (NEU) - присвоить уникальный номер класса эмоции 4\n",
    "        - Sad (SAD) - присвоить уникальный номер класса эмоции 5\n",
    "        \n",
    "        1) Необходимо получить имя файла без расширения.\n",
    "        2) Преобразовать название эмоции в его индекс, например ANG - 0.\n",
    "        \"\"\"\n",
    "\n",
    "        emotions = {\n",
    "            'ANG': 0,\n",
    "            'DIS': 1,\n",
    "            'FEA': 2,\n",
    "            'HAP': 3,\n",
    "            'NEU': 4,\n",
    "            'SAD': 5,\n",
    "        }\n",
    "\n",
    "        n_v = os.path.splitext(os.path.basename(self.path_video))[0]\n",
    "        id_cl = emotions[ n_v.split('_')[-2] ]\n",
    "        return n_v, id_cl\n",
    "    \n",
    "    def makedirs(self, n_v):\n",
    "        \"\"\"\n",
    "        Написать метод, который проверяет, существует ли папка для сохранения кадров и txt файлов.\n",
    "        При отсутствии папки создать ее. Использовать библиотеку os.\n",
    "        Путь для сохранения должен состоять из  self.path_save_ims_txt, n_v.\n",
    "        Пример пути для сохранения кадров и txt файлов: .\\CREMA_D_img_txt\\1010_DFA_ANG_XX\\.\n",
    "        \n",
    "        Работает со:\n",
    "        1) свойством self.path_save_ims_txt\n",
    "        Принимает на вход:\n",
    "        1) имя видеофайла (n_v).\n",
    "        Возвращает:\n",
    "        1) путь (c_path) для сохранения кадров и txt файлов\n",
    "        \"\"\"\n",
    "        c_path = os.path.join(self.path_save_ims_txt, n_v, '')\n",
    "        if not os.path.exists(c_path):\n",
    "            os.makedirs(c_path)\n",
    "        return c_path\n",
    "            \n",
    "    def save_txt(self, c_path: str, n_img: int, line_need: tuple) -> None:\n",
    "        \"\"\"\n",
    "        Написать метод для сохранения line_need в 1 txt файл.\n",
    "        Пример пути для сохранения txt: .\\CREMA_D_img_txt\\1010_DFA_ANG_XX\\000001.txt\n",
    "        \n",
    "        Принимает на вход:\n",
    "        1) путь (c_path) для сохранения кадров и txt файлов\n",
    "        2) текущее имя кадра (n_img) \n",
    "        3) кортеж (line_need)\n",
    "        Возвращает:\n",
    "        1) Ничего\n",
    "        \"\"\"\n",
    "        with open(os.path.join(c_path, n_img) + '.txt', 'w') as f:\n",
    "            # преобразовать line_need, пример:\n",
    "            # из (0, 0.525, 0.451172, 0.3375, 0.511719)\n",
    "            # в '0 0.525 0.451172 0.3375 0.511719\\n'\n",
    "            new_line = ' '.join([str(el) for el in line_need]).strip() + '\\n'\n",
    "            f.write(new_line)\n",
    "            \n",
    "    def save_img(self, c_path, n_img):\n",
    "        \n",
    "        \"\"\"\n",
    "        Написать метод для сохранения кадров.\n",
    "        Пример пути для сохранения кадров: .\\CREMA_D_img_txt\\1010_DFA_ANG_XX\\000010.jpg\n",
    "        \n",
    "        Работает со:\n",
    "        1) свойством self.fr\n",
    "        Принимает на вход:\n",
    "        1) путь (c_path) для сохранения кадров и txt файлов\n",
    "        2) текущее имя кадра (n_img) \n",
    "        Возвращает:\n",
    "        1) Ничего\n",
    "        \"\"\"\n",
    "        cv2.imwrite(os.path.join(c_path, n_img) +'.jpg', self.fr)\n",
    "        \n",
    "    def create_df(self):\n",
    "        \"\"\"\n",
    "        Написать метод проверки существует ли датафрейм с метаданными видео\n",
    "        и при отсутствии датафрейма создать его.\n",
    "        Названия столбцов датафрейма:\n",
    "        name_video - имя файла без расширения\n",
    "        id_classes - индекс эмоции, представленной на видео\n",
    "        speech_duration - продолжительность речи\n",
    "        \n",
    "        Работает со:\n",
    "        1) свойством self.path_save_df\n",
    "        Принимает на вход:\n",
    "        1) Ничего\n",
    "        Возвращает:\n",
    "        1) Ничего\n",
    "        \"\"\"\n",
    "        if not os.path.exists(self.path_save_df):\n",
    "            # создать пустой датафрейм c заданными наименованиями столбцов\n",
    "            df = pd.DataFrame(columns=['name_video', 'id_classes', 'speech_duration'])\n",
    "            # сохранить датафрейм\n",
    "            df.to_csv(self.path_save_df, index=False)\n",
    "    \n",
    "    def get_frame(self):\n",
    "        self.video = cv2.VideoCapture(self.path_video)  \n",
    "        fps = np.round(self.video.get(cv2.CAP_PROP_FPS)) # получаем информацио о fps видео\n",
    "        w = int(self.video.get(cv2.CAP_PROP_FRAME_WIDTH)) # получаем информацио о ширине кадра\n",
    "        h = int(self.video.get(cv2.CAP_PROP_FRAME_HEIGHT)) # получаем информацио о высоте кадра\n",
    "        self.total_frame = int(self.video.get(cv2.CAP_PROP_FRAME_COUNT)) # получаем информацию об общем количестве кадров\n",
    "        \"\"\"\n",
    "        1. Написать и вызвать метод self.get_timestamps для получения начала и конца речи с помощью silero\n",
    "        \"\"\"\n",
    "        start, end = self.get_timestamps()\n",
    "        \"\"\"\n",
    "        2. Перевести время с секунд в кадры. Сформировать список need_frames нужных прореженных кадров, \n",
    "        используя start, end, self.multiple. \n",
    "        \"\"\"\n",
    "        need_frames = list(range( int(start * fps), int(end * fps) + 1, self.multiple ))\n",
    "        \"\"\"\n",
    "        3. Написать и вызвать метод self.get_id_cl()\n",
    "        \"\"\"\n",
    "        n_v, id_cl = self.get_id_cl()\n",
    "        \n",
    "        with mp_face_mesh.FaceMesh(\n",
    "                max_num_faces=1,\n",
    "                refine_landmarks=False,\n",
    "                min_detection_confidence=0.5,\n",
    "                min_tracking_confidence=0.5) as face_mesh:\n",
    "        \n",
    "            for c_fr in need_frames:\n",
    "\n",
    "                self.video.set(cv2.CAP_PROP_POS_FRAMES, c_fr)\n",
    "                _, self.fr = self.video.read()\n",
    "                if self.fr is None: break\n",
    "\n",
    "                self.c_fr = c_fr\n",
    "                    \n",
    "                \"\"\"\n",
    "                4. Написать условие: если текущий кадр self.c_fr есть в списке need_frames, то выполнить обнаружение лица\n",
    "                \"\"\"\n",
    "                n_img = str(self.c_fr).zfill(6)\n",
    "\n",
    "                self.fr.flags.writeable = False\n",
    "                self.fr = cv2.cvtColor(self.fr, cv2.COLOR_BGR2RGB)\n",
    "                results = face_mesh.process(self.fr)\n",
    "\n",
    "                self.fr.flags.writeable = True\n",
    "                self.fr = cv2.cvtColor(self.fr, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                if results.multi_face_landmarks:\n",
    "                    for fl in results.multi_face_landmarks:\n",
    "                        box = self.get_box(fl, w, h) # Дописать код\n",
    "                        newbox = self.norm_box(size=(w, h), box=box) # Дописать код\n",
    "                        line_need = (id_cl, *newbox)\n",
    "                        \"\"\"\n",
    "                        5. Написать и вызвать метод self.makedirs() для сознания пути сохранения изображений и текстовых файлов.\n",
    "                        \"\"\"\n",
    "                        c_path = self.makedirs(n_v = n_v)\n",
    "                        \"\"\"\n",
    "                        6. Написать и вызвать метод self.save_txt() для сохранения текстовых файлов.\n",
    "                        \"\"\"\n",
    "                        self.save_txt(c_path = c_path, n_img = n_img, line_need = line_need)\n",
    "                        \"\"\"\n",
    "                        7. Написать и вызвать метод self.save_img() для сохранения изображений.\n",
    "                        \"\"\"\n",
    "                        self.save_img(c_path = c_path, n_img = n_img)\n",
    "                \n",
    "        \"\"\"\n",
    "        8. Написать и вызвать метод self.create_df() для создания или проверки существования датафрейма с метаданными\n",
    "        \"\"\"        \n",
    "                \n",
    "        self.create_df()\n",
    "        \n",
    "        \"\"\"\n",
    "        9. Сохранить метаданные о видео:\n",
    "        - name_video,\n",
    "        - id_classes,\n",
    "        - speech_duration (указать продолжительность речи, использовать значения start и end)\n",
    "        \"\"\"  \n",
    "        with open(self.path_save_df, 'a+', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter=',')\n",
    "            writer.writerow([n_v, id_cl, end - start])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
