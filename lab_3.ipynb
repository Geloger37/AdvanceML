{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "676f8814-d86a-4e8e-ae60-05c997cebaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import comet_ml\n",
    "import os\n",
    "import torch\n",
    "import lightning\n",
    "import itertools\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from modules.dataset import EMODataset \n",
    "from modules.resnet import generate_model\n",
    "from modules.headless_resnet import generate_model as headless_model\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from lightning.pytorch.loggers import CometLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "882e194f-3be1-4582-b58a-7c4006cd2588",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = EMODataset(img_txt_dir='CREMA_D_img_txt/', subset='train', shape=(300, 400), max_length=8, padding=True)\n",
    "test_ds = EMODataset(img_txt_dir='CREMA_D_img_txt/', subset='test', shape=(300, 400), max_length=8, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d93c8d01-967a-4f87-9fd8-03248422cf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionClassifier(lightning.LightningModule):\n",
    "    def __init__(self, lr: int = None, n_classes: int = None, type_of_resnet: int = None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.n_classes = n_classes\n",
    "        self.type_of_resnet = type_of_resnet\n",
    "\n",
    "        self.resnet = generate_model(type_of_resnet, n_classes=n_classes)\n",
    "\n",
    "        self.loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        self.conf_mat = ConfusionMatrix(task='multiclass', num_classes=n_classes, normalize='true')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        data, labels = batch\n",
    "\n",
    "        outs = self(data)\n",
    "\n",
    "        loss = self.loss(outs, labels)\n",
    "        self.log(\"loss/train\", loss.detach().cpu().item(), prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        data, labels = batch\n",
    "        \n",
    "        outs = self(data)\n",
    "\n",
    "        self.val_outs = torch.cat((self.val_outs, torch.argmax(outs, -1)))\n",
    "        self.val_labels = torch.cat((self.val_labels, labels))\n",
    "\n",
    "        val_loss = self.loss(outs, labels)\n",
    "        self.log(\"loss/val\", val_loss.detach().cpu().item(), prog_bar=True)\n",
    "        \n",
    "        return val_loss\n",
    "\n",
    "    def on_validation_epoch_start(self):\n",
    "        self.val_outs = torch.empty(0, device=self.device)\n",
    "        self.val_labels = torch.empty(0, device=self.device)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        conf_matrix = self.conf_mat(self.val_outs, self.val_labels)\n",
    "        \n",
    "        uar = torch.mean(torch.diagonal(conf_matrix).float()).item()\n",
    "\n",
    "        self.logger.experiment.log_confusion_matrix(y_true=self.val_labels.detach().cpu().numpy().astype(int), y_predicted=self.val_outs.detach().cpu().numpy().astype(int), labels=['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD'])\n",
    "        self.log('uar/val', uar, prog_bar=True)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f652e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadlessEmotionClassifier(lightning.LightningModule):\n",
    "    def __init__(self, lr: int = None, type_of_encoder: str = None, type_of_resnet: int = None, n_classes: int = None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.lr = lr\n",
    "        self.n_classes = n_classes\n",
    "        self.type_of_resnet = type_of_resnet\n",
    "        self.type_of_encoder = type_of_encoder\n",
    "        \n",
    "        self.resnet = headless_model(type_of_resnet)\n",
    "\n",
    "        self.loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        dim = 512\n",
    "        len_of_sequence = 8\n",
    "\n",
    "        if type_of_encoder == 'lstm':\n",
    "            class Post_lstm_layer(torch.nn.Module):\n",
    "                def forward(self, x):\n",
    "                    return x[0]\n",
    "\n",
    "            self.encoder_layer = torch.nn.Sequential(torch.nn.LSTM(512, dim, 1, batch_first=True),\n",
    "                                                     Post_lstm_layer(),\n",
    "                                                     torch.nn.Flatten(start_dim=1),\n",
    "                                                     torch.nn.Linear(len_of_sequence * dim, n_classes))\n",
    "        elif type_of_encoder == 'transformer':\n",
    "            self.encoder_layer = torch.nn.Sequential(torch.nn.TransformerEncoderLayer(d_model=dim, nhead=1, batch_first=True),\n",
    "                                                     torch.nn.Flatten(start_dim=1),\n",
    "                                                     torch.nn.Linear(len_of_sequence * dim, n_classes))\n",
    "\n",
    "        self.conf_mat = ConfusionMatrix(task='multiclass', num_classes=n_classes, normalize='true')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "\n",
    "        x = x.squeeze((3, 4)).permute((0, 2, 1))\n",
    "\n",
    "        x = self.encoder_layer(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        data, labels = batch\n",
    "\n",
    "        outs = self(data)\n",
    "\n",
    "        loss = self.loss(outs, labels)\n",
    "        self.log(\"loss/train\", loss.detach().cpu().item(), prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        data, labels = batch\n",
    "        \n",
    "        outs = self(data)\n",
    "\n",
    "        self.val_outs = torch.cat((self.val_outs, torch.argmax(outs, -1)))\n",
    "        self.val_labels = torch.cat((self.val_labels, labels))\n",
    "\n",
    "        val_loss = self.loss(outs, labels)\n",
    "        self.log(\"loss/val\", val_loss.detach().cpu().item(), prog_bar=True)\n",
    "        \n",
    "        return val_loss\n",
    "        \n",
    "    def on_validation_epoch_start(self):\n",
    "        self.val_outs = torch.empty(0, device=self.device)\n",
    "        self.val_labels = torch.empty(0, device=self.device)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        conf_matrix = self.conf_mat(self.val_outs, self.val_labels)\n",
    "        \n",
    "        uar = torch.mean(torch.diagonal(conf_matrix).float()).item()\n",
    "\n",
    "        self.logger.experiment.log_confusion_matrix(y_true=self.val_labels.detach().cpu().numpy().astype(int), y_predicted=self.val_outs.detach().cpu().numpy().astype(int), labels=['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD'])\n",
    "        self.log('uar/val', uar, prog_bar=True)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51bc00d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_grid_iter(grid):\n",
    "    for param in itertools.product(*grid.values()):\n",
    "        yield dict(zip(grid.keys(), param))\n",
    "\n",
    "hyperparameters = {\n",
    "    'lr': [1e-4, 2e-5],\n",
    "    'epochs': [10, 15],\n",
    "    'batch_size': [16],\n",
    "    'n_classes': [6],\n",
    "    'type_of_resnet': [18]\n",
    "}\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size=hyperparameters['batch_size'][0], num_workers=os.cpu_count())\n",
    "val_dataloader = DataLoader(test_ds, batch_size=hyperparameters['batch_size'][0], num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2b6e0a",
   "metadata": {},
   "source": [
    "Shape of each batch in dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5f183d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 8, 300, 400])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d78fa46",
   "metadata": {},
   "source": [
    "Test default ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d5d757-bae0-4cb8-91bd-f94a2093d368",
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in param_grid_iter(hyperparameters):\n",
    "    comet_logger = CometLogger(\n",
    "        save_dir=\"comet_logs\",\n",
    "        api_key='mir2VfuhUuhr28pomNEh9y7XX',\n",
    "        project_name='AdvancedML-lab-3',\n",
    "        experiment_name=f'RESNET {params}',\n",
    "        offline=True\n",
    "    )\n",
    "\n",
    "    net = EmotionClassifier(lr = params['lr'], n_classes = params['n_classes'], type_of_resnet = params['type_of_resnet'])\n",
    "\n",
    "    comet_logger.log_hyperparams(params)\n",
    "\n",
    "    trainer = lightning.Trainer(max_epochs=params['epochs'], logger=comet_logger)\n",
    "\n",
    "    trainer.fit(net, \n",
    "            train_dataloaders=train_dataloader,\n",
    "            val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659dfe6c",
   "metadata": {},
   "source": [
    "Test ResNet with lstm layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2b2265",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'lr': [1e-4, 2e-5],\n",
    "    'epochs': [10, 15],\n",
    "    'batch_size': [16],\n",
    "    'n_classes': [6],\n",
    "    'type_of_resnet': [18],\n",
    "    'type_of_encoder': ['lstm']\n",
    "}\n",
    "\n",
    "for params in param_grid_iter(hyperparameters):\n",
    "    comet_logger = CometLogger(\n",
    "        save_dir=\"comet_logs\",\n",
    "        api_key='mir2VfuhUuhr28pomNEh9y7XX',\n",
    "        project_name='AdvancedML-lab-3',\n",
    "        experiment_name=f'RESNET-LSTM {params}',\n",
    "        offline=True\n",
    "    )\n",
    "\n",
    "    net = HeadlessEmotionClassifier(lr = params['lr'], n_classes = params['n_classes'], type_of_resnet=params['type_of_resnet'], type_of_encoder=params['type_of_encoder'])\n",
    "\n",
    "    comet_logger.log_hyperparams(params)\n",
    "\n",
    "    trainer = lightning.Trainer(max_epochs=params['epochs'], logger=comet_logger)\n",
    "\n",
    "    trainer.fit(net, \n",
    "            train_dataloaders=train_dataloader,\n",
    "            val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c37609",
   "metadata": {},
   "source": [
    "Train ResNet with transformer encoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55beb3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'lr': [1e-4, 2e-5],\n",
    "    'epochs': [10, 15],\n",
    "    'batch_size': [16],\n",
    "    'n_classes': [6],\n",
    "    'type_of_resnet': [18],\n",
    "    'type_of_encoder': ['transformer']\n",
    "}\n",
    "\n",
    "for params in param_grid_iter(hyperparameters):\n",
    "    comet_logger = CometLogger(\n",
    "        save_dir=\"comet_logs\",\n",
    "        api_key='mir2VfuhUuhr28pomNEh9y7XX',\n",
    "        project_name='AdvancedML-lab-3',\n",
    "        experiment_name=f'RESNET-transformer {params}',\n",
    "        offline=True\n",
    "    )\n",
    "\n",
    "    net = HeadlessEmotionClassifier(lr = params['lr'], n_classes = params['n_classes'], type_of_resnet=params['type_of_resnet'], type_of_encoder=params['type_of_encoder'])\n",
    "\n",
    "    comet_logger.log_hyperparams(params)\n",
    "\n",
    "    trainer = lightning.Trainer(max_epochs=params['epochs'], logger=comet_logger)\n",
    "\n",
    "    trainer.fit(net, \n",
    "            train_dataloaders=train_dataloader,\n",
    "            val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4145fcd2",
   "metadata": {},
   "source": [
    "Test our models on cpu and debug architecture of NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4087b537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([16, 8, 512])\n",
      "torch.Size([16, 8, 512])\n",
      "torch.Size([16, 4096])\n"
     ]
    }
   ],
   "source": [
    "from modules.headless_resnet import generate_model as headless_model\n",
    "\n",
    "mmmm = generate_model(18)\n",
    "\n",
    "with torch.no_grad():\n",
    "    layer = mmmm(next(iter(train_dataloader))[0]).squeeze((3, 4)).permute((0, 2, 1))\n",
    "    print(layer.shape)\n",
    "    # layer, _ = torch.nn.LSTM(512, 256, 1, batch_first=True)(layer)\n",
    "    layer = torch.nn.TransformerEncoderLayer(d_model=512, nhead=4, batch_first=True)(layer)\n",
    "    print(layer.shape)\n",
    "    layer = layer.flatten(start_dim=1)\n",
    "    print(layer.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
